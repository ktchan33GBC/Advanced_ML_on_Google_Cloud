{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Datasets for the Content-based Filter\n",
    "\n",
    "This notebook builds the data you will use for creating our content based model. You'll collect the data via a collection of SQL queries from the publicly available Kurier.at dataset in BigQuery.\n",
    "Kurier.at is an Austrian newsite. The goal of these labs is to recommend an article for a visitor to the site. In this notebook, you collect the data for training, in the subsequent notebook you train the recommender model. \n",
    "\n",
    "This notebook illustrates:\n",
    "* How to pull data from BigQuery table and write to local files.\n",
    "* How to make reproducible train and test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from google.cloud import bigquery \n",
    "\n",
    "PROJECT = 'qwiklabs-gcp-03-9e74f26a3ed5' # REPLACE WITH YOUR PROJECT ID\n",
    "BUCKET = 'qwiklabs-gcp-03-9e74f26a3ed5' # REPLACE WITH YOUR BUCKET NAME\n",
    "REGION = 'us-central1' # REPLACE WITH YOUR BUCKET REGION e.g. us-central1\n",
    "\n",
    "# do not change these\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['REGION'] = REGION\n",
    "os.environ['TFVERSION'] = '2.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-api-core==1.33.2 in /opt/conda/lib/python3.9/site-packages (1.33.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /opt/conda/lib/python3.9/site-packages (from google-api-core==1.33.2) (1.59.1)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5 in /opt/conda/lib/python3.9/site-packages (from google-api-core==1.33.2) (3.19.6)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /opt/conda/lib/python3.9/site-packages (from google-api-core==1.33.2) (1.35.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.9/site-packages (from google-api-core==1.33.2) (2.31.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core==1.33.2) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.9/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core==1.33.2) (0.2.7)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.9/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core==1.33.2) (67.7.2)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.9/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core==1.33.2) (1.15.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.9/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core==1.33.2) (4.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core==1.33.2) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core==1.33.2) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core==1.33.2) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core==1.33.2) (2023.5.7)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-api-core==1.33.2) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "### need to set google-api-core==1.33.2\n",
    "!pip install google-api-core==1.33.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Updated property [compute/region].\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud  config  set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will use this helper function to write lists containing article ids, categories, and authors for each article in our database to local file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_list_to_disk(my_list, filename):\n",
    "  with open(filename, 'w') as f:\n",
    "    for item in my_list:\n",
    "        line = \"%s\\n\" % item\n",
    "        f.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull data from BigQuery\n",
    "\n",
    "The cell below creates a local text file containing all the article ids (i.e. 'content ids') in the dataset. \n",
    "\n",
    "Have a look at the original dataset in [BigQuery](https://console.cloud.google.com/bigquery?p=cloud-training-demos&d=GA360_test&t=ga_sessions_sample). Then read through the query below and make sure you understand what it is doing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some sample content IDs ['298846345', '297944011', '115827617']\n",
      "The total number of articles is 15634\n"
     ]
    }
   ],
   "source": [
    "sql=\"\"\"\n",
    "#standardSQL\n",
    "\n",
    "SELECT  \n",
    "  (SELECT MAX(IF(index=10, value, NULL)) FROM UNNEST(hits.customDimensions)) AS content_id \n",
    "FROM `cloud-training-demos.GA360_test.ga_sessions_sample`,   \n",
    "  UNNEST(hits) AS hits\n",
    "WHERE \n",
    "  # only include hits on pages\n",
    "  hits.type = \"PAGE\"\n",
    "  AND (SELECT MAX(IF(index=10, value, NULL)) FROM UNNEST(hits.customDimensions)) IS NOT NULL\n",
    "GROUP BY\n",
    "  content_id\n",
    "  \n",
    "\"\"\"\n",
    "\n",
    "content_ids_list = bigquery.Client().query(sql).to_dataframe()['content_id'].tolist()\n",
    "write_list_to_disk(content_ids_list, \"content_ids.txt\")\n",
    "print(\"Some sample content IDs {}\".format(content_ids_list[:3]))\n",
    "print(\"The total number of articles is {}\".format(len(content_ids_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There should be 15,634 articles in the database.  \n",
    "Next, you'll create a local file which contains a list of article categories and a list of article authors.\n",
    "\n",
    "Note the change in the index when pulling the article category or author information. Also, you are using the first author of the article to create our author list.  \n",
    "Refer back to the original dataset, use the `hits.customDimensions.index` field to verify the correct index.\t "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Stars & Kultur', 'Lifestyle', 'News']\n"
     ]
    }
   ],
   "source": [
    "sql=\"\"\"\n",
    "#standardSQL\n",
    "SELECT  \n",
    "  (SELECT MAX(IF(index=7, value, NULL)) FROM UNNEST(hits.customDimensions)) AS category  \n",
    "FROM `cloud-training-demos.GA360_test.ga_sessions_sample`,   \n",
    "  UNNEST(hits) AS hits\n",
    "WHERE \n",
    "  # only include hits on pages\n",
    "  hits.type = \"PAGE\"\n",
    "  AND (SELECT MAX(IF(index=7, value, NULL)) FROM UNNEST(hits.customDimensions)) IS NOT NULL\n",
    "GROUP BY   \n",
    "  category\n",
    "\"\"\"\n",
    "categories_list = bigquery.Client().query(sql).to_dataframe()['category'].tolist()\n",
    "write_list_to_disk(categories_list, \"categories.txt\")\n",
    "print(categories_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The categories are 'News', 'Stars & Kultur', and 'Lifestyle'.  \n",
    "When creating the author list, you'll only use the first author information for each article.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some sample authors ['Elisabeth Spitzer', 'Raffaela Lindorfer', 'Peter Karlik', 'Georg Leyrer', 'Mathias Kainz', 'Stefan Berndl', 'Karl Oberascher', 'Klaus Knittelfelder', 'Moritz Gottsauner-Wolf', 'Daniela Wahl']\n",
      "The total number of authors is 385\n"
     ]
    }
   ],
   "source": [
    "sql=\"\"\"\n",
    "#standardSQL\n",
    "SELECT\n",
    "  REGEXP_EXTRACT((SELECT MAX(IF(index=2, value, NULL)) FROM UNNEST(hits.customDimensions)), r\"^[^,]+\")  AS first_author  \n",
    "FROM `cloud-training-demos.GA360_test.ga_sessions_sample`,   \n",
    "  UNNEST(hits) AS hits\n",
    "WHERE \n",
    "  # only include hits on pages\n",
    "  hits.type = \"PAGE\"\n",
    "  AND (SELECT MAX(IF(index=2, value, NULL)) FROM UNNEST(hits.customDimensions)) IS NOT NULL\n",
    "GROUP BY   \n",
    "  first_author\n",
    "\"\"\"\n",
    "authors_list = bigquery.Client().query(sql).to_dataframe()['first_author'].tolist()\n",
    "write_list_to_disk(authors_list, \"authors.txt\")\n",
    "print(\"Some sample authors {}\".format(authors_list[:10]))\n",
    "print(\"The total number of authors is {}\".format(len(authors_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There should be 385 authors in the database. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train and test sets\n",
    "\n",
    "In this section, you will create the train/test split of our data for training our model. You use the concatenated values for visitor id and content id to create a farm fingerprint, taking approximately 90% of the data for the training set and 10% for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visitor_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>months_since_epoch</th>\n",
       "      <th>next_content_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1049534290319968384</td>\n",
       "      <td>299946732</td>\n",
       "      <td>News</td>\n",
       "      <td>\"Explosiver\" Mieter soll aus Groll seine Wohnu...</td>\n",
       "      <td>Ricardo Peyerl</td>\n",
       "      <td>574</td>\n",
       "      <td>299946732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1049534290319968384</td>\n",
       "      <td>299946732</td>\n",
       "      <td>News</td>\n",
       "      <td>\"Explosiver\" Mieter soll aus Groll seine Wohnu...</td>\n",
       "      <td>Ricardo Peyerl</td>\n",
       "      <td>574</td>\n",
       "      <td>299969709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1049534290319968384</td>\n",
       "      <td>268707300</td>\n",
       "      <td>Lifestyle</td>\n",
       "      <td>Manspreading: Madrid geht gegen breitbeinige S...</td>\n",
       "      <td>Marlene Patsalidis</td>\n",
       "      <td>569</td>\n",
       "      <td>268707300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1049534290319968384</td>\n",
       "      <td>268707300</td>\n",
       "      <td>Lifestyle</td>\n",
       "      <td>Manspreading: Madrid geht gegen breitbeinige S...</td>\n",
       "      <td>Marlene Patsalidis</td>\n",
       "      <td>569</td>\n",
       "      <td>299925700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1060199256712239175</td>\n",
       "      <td>299804373</td>\n",
       "      <td>Lifestyle</td>\n",
       "      <td>Bloggerin wegen Anstiftung zur Magersucht ange...</td>\n",
       "      <td>Elisabeth Mittendorfer</td>\n",
       "      <td>574</td>\n",
       "      <td>299772450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            visitor_id content_id   category  \\\n",
       "0  1049534290319968384  299946732       News   \n",
       "1  1049534290319968384  299946732       News   \n",
       "2  1049534290319968384  268707300  Lifestyle   \n",
       "3  1049534290319968384  268707300  Lifestyle   \n",
       "4  1060199256712239175  299804373  Lifestyle   \n",
       "\n",
       "                                               title                  author  \\\n",
       "0  \"Explosiver\" Mieter soll aus Groll seine Wohnu...          Ricardo Peyerl   \n",
       "1  \"Explosiver\" Mieter soll aus Groll seine Wohnu...          Ricardo Peyerl   \n",
       "2  Manspreading: Madrid geht gegen breitbeinige S...      Marlene Patsalidis   \n",
       "3  Manspreading: Madrid geht gegen breitbeinige S...      Marlene Patsalidis   \n",
       "4  Bloggerin wegen Anstiftung zur Magersucht ange...  Elisabeth Mittendorfer   \n",
       "\n",
       "   months_since_epoch next_content_id  \n",
       "0                 574       299946732  \n",
       "1                 574       299969709  \n",
       "2                 569       268707300  \n",
       "3                 569       299925700  \n",
       "4                 574       299772450  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql=\"\"\"\n",
    "WITH site_history as (\n",
    "  SELECT\n",
    "      fullVisitorId as visitor_id,\n",
    "      (SELECT MAX(IF(index=10, value, NULL)) FROM UNNEST(hits.customDimensions)) AS content_id,\n",
    "      (SELECT MAX(IF(index=7, value, NULL)) FROM UNNEST(hits.customDimensions)) AS category, \n",
    "      (SELECT MAX(IF(index=6, value, NULL)) FROM UNNEST(hits.customDimensions)) AS title,\n",
    "      (SELECT MAX(IF(index=2, value, NULL)) FROM UNNEST(hits.customDimensions)) AS author_list,\n",
    "      SPLIT(RPAD((SELECT MAX(IF(index=4, value, NULL)) FROM UNNEST(hits.customDimensions)), 7), '.') as year_month_array,\n",
    "      LEAD(hits.customDimensions, 1) OVER (PARTITION BY fullVisitorId ORDER BY hits.time ASC) as nextCustomDimensions\n",
    "  FROM \n",
    "    `cloud-training-demos.GA360_test.ga_sessions_sample`,   \n",
    "     UNNEST(hits) AS hits\n",
    "   WHERE \n",
    "     # only include hits on pages\n",
    "      hits.type = \"PAGE\"\n",
    "      AND\n",
    "      fullVisitorId IS NOT NULL\n",
    "      AND\n",
    "      hits.time != 0\n",
    "      AND\n",
    "      hits.time IS NOT NULL\n",
    "      AND\n",
    "      (SELECT MAX(IF(index=10, value, NULL)) FROM UNNEST(hits.customDimensions)) IS NOT NULL\n",
    ")\n",
    "SELECT\n",
    "  visitor_id,\n",
    "  content_id,\n",
    "  category,\n",
    "  REGEXP_REPLACE(title, r\",\", \"\") as title,\n",
    "  REGEXP_EXTRACT(author_list, r\"^[^,]+\") as author,\n",
    "  DATE_DIFF(DATE(CAST(year_month_array[OFFSET(0)] AS INT64), CAST(year_month_array[OFFSET(1)] AS INT64), 1), DATE(1970,1,1), MONTH) as months_since_epoch,\n",
    "  (SELECT MAX(IF(index=10, value, NULL)) FROM UNNEST(nextCustomDimensions)) as next_content_id\n",
    "FROM\n",
    "  site_history\n",
    "WHERE (SELECT MAX(IF(index=10, value, NULL)) FROM UNNEST(nextCustomDimensions)) IS NOT NULL\n",
    "      AND ABS(MOD(FARM_FINGERPRINT(CONCAT(visitor_id, content_id)), 10)) < 9\n",
    "\"\"\"\n",
    "training_set_df = bigquery.Client().query(sql).to_dataframe()\n",
    "training_set_df.to_csv('training_set.csv', header=False, index=False, encoding='utf-8')\n",
    "training_set_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visitor_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>months_since_epoch</th>\n",
       "      <th>next_content_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1019158988689919195</td>\n",
       "      <td>299833903</td>\n",
       "      <td>News</td>\n",
       "      <td>Ungarns Regierung kämpft mit Buch gegen Soros</td>\n",
       "      <td>Peter Temel</td>\n",
       "      <td>574</td>\n",
       "      <td>299816215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>118772017798034869</td>\n",
       "      <td>299838010</td>\n",
       "      <td>News</td>\n",
       "      <td>Doch plus 233 Prozent  für Großteil der Beamten</td>\n",
       "      <td>Wolfgang Atzenhofer</td>\n",
       "      <td>574</td>\n",
       "      <td>299451483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1228262559676487843</td>\n",
       "      <td>299818044</td>\n",
       "      <td>News</td>\n",
       "      <td>Lehrer am Gymnasium Schwechat suspendiert</td>\n",
       "      <td>None</td>\n",
       "      <td>574</td>\n",
       "      <td>272595271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464829057720768794</td>\n",
       "      <td>254619647</td>\n",
       "      <td>None</td>\n",
       "      <td>ANB</td>\n",
       "      <td>None</td>\n",
       "      <td>566</td>\n",
       "      <td>299826775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1555557450090689676</td>\n",
       "      <td>299818044</td>\n",
       "      <td>News</td>\n",
       "      <td>Lehrer am Gymnasium Schwechat suspendiert</td>\n",
       "      <td>None</td>\n",
       "      <td>574</td>\n",
       "      <td>299853016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            visitor_id content_id category  \\\n",
       "0  1019158988689919195  299833903     News   \n",
       "1   118772017798034869  299838010     News   \n",
       "2  1228262559676487843  299818044     News   \n",
       "3  1464829057720768794  254619647     None   \n",
       "4  1555557450090689676  299818044     News   \n",
       "\n",
       "                                             title               author  \\\n",
       "0    Ungarns Regierung kämpft mit Buch gegen Soros          Peter Temel   \n",
       "1  Doch plus 233 Prozent  für Großteil der Beamten  Wolfgang Atzenhofer   \n",
       "2        Lehrer am Gymnasium Schwechat suspendiert                 None   \n",
       "3                                              ANB                 None   \n",
       "4        Lehrer am Gymnasium Schwechat suspendiert                 None   \n",
       "\n",
       "   months_since_epoch next_content_id  \n",
       "0                 574       299816215  \n",
       "1                 574       299451483  \n",
       "2                 574       272595271  \n",
       "3                 566       299826775  \n",
       "4                 574       299853016  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql=\"\"\"\n",
    "WITH site_history as (\n",
    "  SELECT\n",
    "      fullVisitorId as visitor_id,\n",
    "      (SELECT MAX(IF(index=10, value, NULL)) FROM UNNEST(hits.customDimensions)) AS content_id,\n",
    "      (SELECT MAX(IF(index=7, value, NULL)) FROM UNNEST(hits.customDimensions)) AS category, \n",
    "      (SELECT MAX(IF(index=6, value, NULL)) FROM UNNEST(hits.customDimensions)) AS title,\n",
    "      (SELECT MAX(IF(index=2, value, NULL)) FROM UNNEST(hits.customDimensions)) AS author_list,\n",
    "      SPLIT(RPAD((SELECT MAX(IF(index=4, value, NULL)) FROM UNNEST(hits.customDimensions)), 7), '.') as year_month_array,\n",
    "      LEAD(hits.customDimensions, 1) OVER (PARTITION BY fullVisitorId ORDER BY hits.time ASC) as nextCustomDimensions\n",
    "  FROM \n",
    "    `cloud-training-demos.GA360_test.ga_sessions_sample`,   \n",
    "     UNNEST(hits) AS hits\n",
    "   WHERE \n",
    "     # only include hits on pages\n",
    "      hits.type = \"PAGE\"\n",
    "      AND\n",
    "      fullVisitorId IS NOT NULL\n",
    "      AND\n",
    "      hits.time != 0\n",
    "      AND\n",
    "      hits.time IS NOT NULL\n",
    "      AND\n",
    "      (SELECT MAX(IF(index=10, value, NULL)) FROM UNNEST(hits.customDimensions)) IS NOT NULL\n",
    ")\n",
    "SELECT\n",
    "  visitor_id,\n",
    "  content_id,\n",
    "  category,\n",
    "  REGEXP_REPLACE(title, r\",\", \"\") as title,\n",
    "  REGEXP_EXTRACT(author_list, r\"^[^,]+\") as author,\n",
    "  DATE_DIFF(DATE(CAST(year_month_array[OFFSET(0)] AS INT64), CAST(year_month_array[OFFSET(1)] AS INT64), 1), DATE(1970,1,1), MONTH) as months_since_epoch,\n",
    "  (SELECT MAX(IF(index=10, value, NULL)) FROM UNNEST(nextCustomDimensions)) as next_content_id\n",
    "FROM\n",
    "  site_history\n",
    "WHERE (SELECT MAX(IF(index=10, value, NULL)) FROM UNNEST(nextCustomDimensions)) IS NOT NULL\n",
    "      AND ABS(MOD(FARM_FINGERPRINT(CONCAT(visitor_id, content_id)), 10)) >= 9\n",
    "\"\"\"\n",
    "test_set_df = bigquery.Client().query(sql).to_dataframe()\n",
    "test_set_df.to_csv('test_set.csv', header=False, index=False, encoding='utf-8')\n",
    "test_set_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the two csv files you just created containing the training and test set. You'll also do a line count of both files to confirm that you have achieved an approximate 90/10 train/test split.  \n",
    "In the next notebook, **Content Based Filtering** you will build a model to recommend an article given information about the current article being read, such as the category, title, author, and publish date. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   25599 test_set.csv\n",
      "  232308 training_set.csv\n",
      "  257907 total\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "wc -l *_set.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> test_set.csv <==\n",
      "1019158988689919195,299833903,News,Ungarns Regierung kämpft mit Buch gegen Soros,Peter Temel,574,299816215\n",
      "118772017798034869,299838010,News,Doch plus 233 Prozent  für Großteil der Beamten,Wolfgang Atzenhofer,574,299451483\n",
      "1228262559676487843,299818044,News,Lehrer am Gymnasium Schwechat suspendiert,,574,272595271\n",
      "1464829057720768794,254619647,,ANB,,566,299826775\n",
      "1555557450090689676,299818044,News,Lehrer am Gymnasium Schwechat suspendiert,,574,299853016\n",
      "1555557450090689676,299435706,Lifestyle,Diese Bloggerin weiß wie man Fehlkäufe vermeidet,Gabriele Kuhn,574,299943437\n",
      "1964842686378339773,299828023,News,Glyphosat geht in die Verlängerung,Andreas Anzenberger,574,299831571\n",
      "2036370972892179839,299817990,News,Kolumne Anstoß: Das Allerheiligste,Philipp Albrechtsberger,574,299939900\n",
      "210110321307411584,299809186,Lifestyle,Ugly Sweater-WM: Wer hat den hässlichsten Weihnachts-Look?,Maria Zelenko,574,299410466\n",
      "2292459398710009319,299939897,News,Drohnen-Sicherheitspaket präsentiert,,574,299945652\n",
      "\n",
      "==> training_set.csv <==\n",
      "1049534290319968384,299946732,News,\"\"\"Explosiver\"\" Mieter soll aus Groll seine Wohnung in die Luft gesprengt haben\",Ricardo Peyerl,574,299946732\n",
      "1049534290319968384,299946732,News,\"\"\"Explosiver\"\" Mieter soll aus Groll seine Wohnung in die Luft gesprengt haben\",Ricardo Peyerl,574,299969709\n",
      "1049534290319968384,268707300,Lifestyle,Manspreading: Madrid geht gegen breitbeinige Sitzer vor,Marlene Patsalidis,569,268707300\n",
      "1049534290319968384,268707300,Lifestyle,Manspreading: Madrid geht gegen breitbeinige Sitzer vor,Marlene Patsalidis,569,299925700\n",
      "1060199256712239175,299804373,Lifestyle,Bloggerin wegen Anstiftung zur Magersucht angezeigt,Elisabeth Mittendorfer,574,299772450\n",
      "1066191818466341668,299781837,News,Mordalarm in Wien: 31 Jahre alte Frau erstochen,,574,299913368\n",
      "1066191818466341668,299900347,News,Drei Tote bei Explosion in Gebäude in Vorort von Tel Aviv,,574,299899396\n",
      "1066191818466341668,299283414,Lifestyle,Florian Holzer: Top 5: Lebzeltereien,Florian Holzer,574,299777664\n",
      "1066191818466341668,299777664,Stars & Kultur,Kunsthistorisches Museum: Ausstellungen 2018,,574,299777664\n",
      "1089006826476560775,299173332,Stars & Kultur,Verändert: So sehen die 80er-Stars heute aus,Christina Michlits,574,299775313\n"
     ]
    }
   ],
   "source": [
    "!head *_set.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
